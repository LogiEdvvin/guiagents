{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and constants\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import urllib\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "\n",
    "DEFAULT_SECRETS_DIR = os.path.join('../configs', 'secrets.yaml')\n",
    "PUBLISHED_AFTER = datetime.strptime(\"1/1/2017\", '%d/%m/%Y').isoformat() + 'Z'\n",
    "MAX_PAGE_SIZE = 50 # no benefit if this number is anything other than 50\n",
    "VIDEO_DOWNLOAD_DIRECTORY=\"../data/youtube_dataset/videos\"\n",
    "VIDEO_DATA_PATH=\"../data/youtube_dataset/video_data.json\"\n",
    "TRANSCRIPT_DOWNLOAD_DIRECTORY = r\"C:\\Users\\emaid\\Desktop\\guiagents\\data\\youtube_dataset\\transcripts\"\n",
    "CACHE_PATH = \"../data/cache\"\n",
    "GOOGLE_API_CLIENT_SECRETS_FILE = \"../configs/client_secret_google_api.json\"\n",
    "YOLO_MODEL_PATH = r\"C:\\\\Users\\\\emaid\\\\Desktop\\\\guiagents\\\\data\\\\yolo_element_detector\\\\training\\\\train11\\\\weights\\\\best.pt\"\n",
    "YOLO_TRACKING_FRAME_STEP = 3 # every how many frames apply yolo tracking\n",
    "YOLO_CONFIDENCE_THRESH = 0.5\n",
    "YOLO_RESULTS_DIR = \"../data/youtube_dataset/mouse_tracking\"\n",
    "TRAIN_DATA_PATH = r\"C:\\Users\\emaid\\Desktop\\guiagents\\data\\youtube_dataset\\video_data_train.json\"\n",
    "VAL_DATA_PATH = r\"C:\\Users\\emaid\\Desktop\\guiagents\\data\\youtube_dataset\\video_data_val.json\"\n",
    "TEST_DATA_PATH = r\"C:\\Users\\emaid\\Desktop\\guiagents\\data\\youtube_dataset\\video_data_test.json\"\n",
    "\n",
    "def load_video_data(data_path=VIDEO_DATA_PATH):\n",
    "    if os.path.exists(VIDEO_DATA_PATH):\n",
    "        vid_df = pd.read_json(VIDEO_DATA_PATH, orient='index')\n",
    "        vid_df.index.name = 'id'\n",
    "        vid_df.publish_date = pd.to_datetime(vid_df.publish_date)\n",
    "        return vid_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def store_video_data(vid_df: pd.DataFrame, data_path=VIDEO_DATA_PATH):\n",
    "    vid_df.publish_date = vid_df.publish_date.apply(lambda x : x.isoformat())\n",
    "    vid_df.to_json(data_path, indent=4, orient=\"index\")\n",
    "\n",
    "def parse_video_file(video_path):\n",
    "    match = re.match(r\"\\[(.+)\\]_(.*)\", os.path.basename(video_path))\n",
    "    return {\n",
    "        'id': match.group(1),\n",
    "        'video_name': match.group(2)\n",
    "    }\n",
    "\n",
    "#def list_all_video_files(video_download_dir=VIDEO_DOWNLOAD_DIRECTORY):\n",
    "    #downloaded_ids = glob(os.path.join(video_download_dir, \"*.mp4\"))\n",
    "    #downloaded_ids = set(map(lambda x: x['id'], downloaded_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>video_title</th>\n",
       "      <th>video_description</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>video_tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>channel_subs_count</th>\n",
       "      <th>channel_view_count</th>\n",
       "      <th>channel_vid_count</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S-nHYzK-BVg</th>\n",
       "      <td>2017-09-25 13:12:22+00:00</td>\n",
       "      <td>Beginner's Guide to Microsoft Word</td>\n",
       "      <td>If you like this video, here's my entire playl...</td>\n",
       "      <td>Technology for Teachers and Students</td>\n",
       "      <td>[microsoft word, word tutorial, using ms word,...</td>\n",
       "      <td>6973801</td>\n",
       "      <td>88277.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>1480000</td>\n",
       "      <td>141834118</td>\n",
       "      <td>522</td>\n",
       "      <td>UCYUPLUCkMiUgiyVuluCc7tQ</td>\n",
       "      <td>windows tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHq3bqowzW0</th>\n",
       "      <td>2018-08-31 01:32:47+00:00</td>\n",
       "      <td>How to Clean C Drive In Windows 10  (Make Your...</td>\n",
       "      <td>This video shows you, How to Clean C Drive (Lo...</td>\n",
       "      <td>Geeks Tutorial</td>\n",
       "      <td>[how to clean local disk c windows 10, how to ...</td>\n",
       "      <td>9910893</td>\n",
       "      <td>202666.0</td>\n",
       "      <td>8536.0</td>\n",
       "      <td>558000</td>\n",
       "      <td>84677874</td>\n",
       "      <td>109</td>\n",
       "      <td>UCU1K6P1M8hq-TBnDlHQtO7A</td>\n",
       "      <td>windows tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EJHKuwBhdB4</th>\n",
       "      <td>2024-02-07 14:45:00+00:00</td>\n",
       "      <td>How to Create a Windows 10 Installation USB wi...</td>\n",
       "      <td>In this tutorial video, I'll show you how to c...</td>\n",
       "      <td>Memory's Tech Tips</td>\n",
       "      <td>[how to create a windows 10 installation usb, ...</td>\n",
       "      <td>29995</td>\n",
       "      <td>354.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>13100</td>\n",
       "      <td>3192330</td>\n",
       "      <td>394</td>\n",
       "      <td>UCpFxsy-mzKIIX14aOH-veXg</td>\n",
       "      <td>windows tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fFe3iESppag</th>\n",
       "      <td>2022-04-13 22:32:33+00:00</td>\n",
       "      <td>How to Clean C Drive In Windows 11 (Make Your ...</td>\n",
       "      <td>This video shows you, How to Clean C Drive (Lo...</td>\n",
       "      <td>Geeks Tutorial</td>\n",
       "      <td>[how to clean local disk c windows 11, how to ...</td>\n",
       "      <td>440892</td>\n",
       "      <td>7991.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>558000</td>\n",
       "      <td>84677874</td>\n",
       "      <td>109</td>\n",
       "      <td>UCU1K6P1M8hq-TBnDlHQtO7A</td>\n",
       "      <td>windows tutorial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ttiA0zRbzko</th>\n",
       "      <td>2018-05-05 15:19:14+00:00</td>\n",
       "      <td>How to Speed Up Your Windows 10 Performance! (...</td>\n",
       "      <td>This video shows you, How to speed up any Wind...</td>\n",
       "      <td>Geeks Tutorial</td>\n",
       "      <td>[how to speed up windows 10, speed up windows ...</td>\n",
       "      <td>4112471</td>\n",
       "      <td>85921.0</td>\n",
       "      <td>4556.0</td>\n",
       "      <td>558000</td>\n",
       "      <td>84677874</td>\n",
       "      <td>109</td>\n",
       "      <td>UCU1K6P1M8hq-TBnDlHQtO7A</td>\n",
       "      <td>windows tutorial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         publish_date  \\\n",
       "id                                      \n",
       "S-nHYzK-BVg 2017-09-25 13:12:22+00:00   \n",
       "DHq3bqowzW0 2018-08-31 01:32:47+00:00   \n",
       "EJHKuwBhdB4 2024-02-07 14:45:00+00:00   \n",
       "fFe3iESppag 2022-04-13 22:32:33+00:00   \n",
       "ttiA0zRbzko 2018-05-05 15:19:14+00:00   \n",
       "\n",
       "                                                   video_title  \\\n",
       "id                                                               \n",
       "S-nHYzK-BVg                 Beginner's Guide to Microsoft Word   \n",
       "DHq3bqowzW0  How to Clean C Drive In Windows 10  (Make Your...   \n",
       "EJHKuwBhdB4  How to Create a Windows 10 Installation USB wi...   \n",
       "fFe3iESppag  How to Clean C Drive In Windows 11 (Make Your ...   \n",
       "ttiA0zRbzko  How to Speed Up Your Windows 10 Performance! (...   \n",
       "\n",
       "                                             video_description  \\\n",
       "id                                                               \n",
       "S-nHYzK-BVg  If you like this video, here's my entire playl...   \n",
       "DHq3bqowzW0  This video shows you, How to Clean C Drive (Lo...   \n",
       "EJHKuwBhdB4  In this tutorial video, I'll show you how to c...   \n",
       "fFe3iESppag  This video shows you, How to Clean C Drive (Lo...   \n",
       "ttiA0zRbzko  This video shows you, How to speed up any Wind...   \n",
       "\n",
       "                                    channel_title  \\\n",
       "id                                                  \n",
       "S-nHYzK-BVg  Technology for Teachers and Students   \n",
       "DHq3bqowzW0                        Geeks Tutorial   \n",
       "EJHKuwBhdB4                    Memory's Tech Tips   \n",
       "fFe3iESppag                        Geeks Tutorial   \n",
       "ttiA0zRbzko                        Geeks Tutorial   \n",
       "\n",
       "                                                    video_tags  view_count  \\\n",
       "id                                                                           \n",
       "S-nHYzK-BVg  [microsoft word, word tutorial, using ms word,...     6973801   \n",
       "DHq3bqowzW0  [how to clean local disk c windows 10, how to ...     9910893   \n",
       "EJHKuwBhdB4  [how to create a windows 10 installation usb, ...       29995   \n",
       "fFe3iESppag  [how to clean local disk c windows 11, how to ...      440892   \n",
       "ttiA0zRbzko  [how to speed up windows 10, speed up windows ...     4112471   \n",
       "\n",
       "             like_count  comments_count  channel_subs_count  \\\n",
       "id                                                            \n",
       "S-nHYzK-BVg     88277.0          1891.0             1480000   \n",
       "DHq3bqowzW0    202666.0          8536.0              558000   \n",
       "EJHKuwBhdB4       354.0            38.0               13100   \n",
       "fFe3iESppag      7991.0           291.0              558000   \n",
       "ttiA0zRbzko     85921.0          4556.0              558000   \n",
       "\n",
       "             channel_view_count  channel_vid_count                channel_id  \\\n",
       "id                                                                             \n",
       "S-nHYzK-BVg           141834118                522  UCYUPLUCkMiUgiyVuluCc7tQ   \n",
       "DHq3bqowzW0            84677874                109  UCU1K6P1M8hq-TBnDlHQtO7A   \n",
       "EJHKuwBhdB4             3192330                394  UCpFxsy-mzKIIX14aOH-veXg   \n",
       "fFe3iESppag            84677874                109  UCU1K6P1M8hq-TBnDlHQtO7A   \n",
       "ttiA0zRbzko            84677874                109  UCU1K6P1M8hq-TBnDlHQtO7A   \n",
       "\n",
       "                        query  \n",
       "id                             \n",
       "S-nHYzK-BVg  windows tutorial  \n",
       "DHq3bqowzW0  windows tutorial  \n",
       "EJHKuwBhdB4  windows tutorial  \n",
       "fFe3iESppag  windows tutorial  \n",
       "ttiA0zRbzko  windows tutorial  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load video_data if it already exists\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "vid_df = load_video_data(VIDEO_DATA_PATH)\n",
    "if not vid_df is None:\n",
    "    display(vid_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search youtube "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "queries = [\n",
    "  \"windows tutorial\",\n",
    "  \"linux tutorial\",\n",
    "  \"macos tutorial\",\n",
    "  \"pandas python tutorial\",\n",
    "  \"how to create an account on tutorial\",\n",
    "  \"how to download tutorial computer\",\n",
    "  \"PowerPoint presentation tutorial\",\n",
    "  \"Git and GitHub tutorial\",\n",
    "  \"PowerPoint presentation tutorial\",\n",
    "  \"Building a website with WordPress tutorial\",\n",
    "  \"Creating macros in Excel tutorial\",\n",
    "  \"CAD design with AutoCAD tutorial\",\n",
    "  \"Animating with Adobe Animate tutorial\",\n",
    "  \"how to install C++ tutorial\",\n",
    "  \"how to install java tutorial\",\n",
    "  \"GIMP photo manipulation tutorial\",\n",
    "  \"Creating music with FL Studio tutorial\",\n",
    "  \"Creating animations in Maya tutorial\",\n",
    "  \"Configuring a VPN tutorial\",\n",
    "  \"Audacity tutorial\",\n",
    "  \"Learning to code with Scratch tutorial\",\n",
    "  \"zoom online meetings tutorial\",\n",
    "  \"how to use zoom tutorial\"\n",
    "]\n",
    "\n",
    "with open(DEFAULT_SECRETS_DIR, 'r') as secrets_file:\n",
    "    secrets = yaml.safe_load(secrets_file)\n",
    "\n",
    "yt_api_key = secrets['youtube_api_key']\n",
    "videos = []\n",
    "\n",
    "with build('YouTube', \"v3\", developerKey=yt_api_key) as yt:\n",
    "    for query in queries:\n",
    "\n",
    "        if query in list(vid_df['query'].unique()): # check if query already used\n",
    "            continue\n",
    "\n",
    "        search_result_list = yt.search().list(\n",
    "            part='snippet',\n",
    "            publishedAfter=PUBLISHED_AFTER,\n",
    "            order='relevance',\n",
    "            q=query,\n",
    "            type='video',\n",
    "            videoCategoryId='26',\n",
    "            videoCaption=\"closedCaption\",\n",
    "            maxResults=MAX_PAGE_SIZE,\n",
    "            relevanceLanguage='en',\n",
    "        ).execute()\n",
    "\n",
    "        video_ids = [search_result['id']['videoId'] for search_result in search_result_list['items']]\n",
    "        video_results = yt.videos().list(part=['id', 'snippet', 'statistics'], id=video_ids).execute()\n",
    "        video_results_dict = {video_data['id']:video_data for video_data in video_results['items']}\n",
    "\n",
    "        channel_ids = [video['snippet']['channelId'] for video in video_results['items']]\n",
    "        channel_results = yt.channels().list(part=['statistics'], id=channel_ids).execute()\n",
    "        channel_results_dict = {channel_data['id']:channel_data for channel_data in channel_results['items']}\n",
    "\n",
    "        for video_id, channel_id in zip(video_ids, channel_ids):\n",
    "            video_data = video_results_dict[video_id]\n",
    "            channel_data = channel_results_dict[channel_id]\n",
    "            videos.append(\n",
    "                {\n",
    "                    \"id\": video_data['id'],\n",
    "                    \"publish_date\": video_data['snippet'].get('publishedAt', None),\n",
    "                    \"video_title\": video_data['snippet'].get('title', None),\n",
    "                    \"video_description\": video_data['snippet'].get('description', None),\n",
    "                    \"channel_title\": video_data['snippet'].get('channelTitle', None),\n",
    "                    \"video_tags\": video_data['snippet'].get('tags', None),\n",
    "                    \"view_count\" : video_data['statistics'].get('viewCount', None),\n",
    "                    \"like_count\" : video_data['statistics'].get('likeCount', None),\n",
    "                    \"comments_count\": video_data['statistics'].get('commentCount', None),\n",
    "                    \"channel_subs_count\": channel_data['statistics'].get('subscriberCount', None),\n",
    "                    \"channel_view_count\": channel_data['statistics'].get('viewCount', None),\n",
    "                    \"channel_vid_count\": channel_data['statistics'].get('videoCount', None),\n",
    "                    \"channel_id\": channel_id,\n",
    "                    \"query\": query\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new videos have been found on youtube.\n",
      "1053 is the new number of videos in dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# saving video data\n",
    "vid_df_new = pd.DataFrame(videos).drop_duplicates(subset='id', keep='first').set_index('id')\n",
    "vid_df_new.publish_date = pd.to_datetime(vid_df_new.publish_date)\n",
    "if not vid_df is None:\n",
    "    vid_df_new = vid_df_new.loc[~vid_df_new.index.isin(vid_df.index)]\n",
    "    if(len(vid_df_new) > 0):\n",
    "        vid_df = pd.concat([vid_df, vid_df_new])\n",
    "    print(f\"{len(vid_df_new)} new videos have been found on youtube.\")\n",
    "    print(f\"{len(vid_df)} is the new number of videos in dataset.\")\n",
    "\n",
    "store_video_data(vid_df, VIDEO_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video_data if starting notebook from here\n",
    "vid_df = load_video_data(VIDEO_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey patch to make pytube work again\n",
    "# pytube is occisionally broken and needs monkey patching\n",
    "from pytube import YouTube\n",
    "from pytube.innertube import InnerTube\n",
    "\n",
    "def bypass_age_gate(self):\n",
    "        \"\"\"Attempt to update the vid_info by bypassing the age gate.\"\"\"\n",
    "        clients = [\n",
    "            'ANDROID_EMBED', 'IOS', 'ANDROID', 'WEB_EMBED',\n",
    "            'ANDROID_EMBED', 'IOS_EMBED', 'WEB_MUSIC',\n",
    "            'IOS_MUSIC', 'WEB_CREATOR', 'ANDROID_CREATOR',\n",
    "            'IOS_CREATOR', 'MWEB', 'TV_EMBED', 'WEB'\n",
    "        ]\n",
    "        print(\"Clients List:\\n\\n\", clients,\"\\n\")\n",
    "        success_client = None\n",
    "        try:\n",
    "            for client in clients:\n",
    "                innertube = InnerTube(\n",
    "                    client=client,\n",
    "                    use_oauth=self.use_oauth,\n",
    "                    allow_cache=self.allow_oauth_cache\n",
    "                )\n",
    "                innertube_response = innertube.player(self.video_id)\n",
    "\n",
    "                playability_status = innertube_response['playabilityStatus'].get('status', None)\n",
    "\n",
    "                # Print the status of each client\n",
    "                print(f\"Client: {client}, Status: {playability_status}\")\n",
    "\n",
    "                # If the video is accessible, update _vid_info and exit the loop\n",
    "                if playability_status != 'UNPLAYABLE':\n",
    "                    self._vid_info = innertube_response\n",
    "                    success_client = client\n",
    "                    print(f\"Chosen client: {client}\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        finally:\n",
    "            if not success_client:\n",
    "                print(\"No successful client found. Performing generic action...\")\n",
    "                # Perform generic action here\n",
    "\n",
    "YouTube.bypass_age_gate = bypass_age_gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pytube import YouTube\n",
    "\n",
    "# retrieve all downloaded ids\n",
    "downloaded_ids = glob(os.path.join(VIDEO_DOWNLOAD_DIRECTORY, \"*.mp4\"))\n",
    "downloaded_ids = set(map(lambda x: parse_video_file(x)['id'], downloaded_ids))\n",
    "\n",
    "for vid_id in tqdm(vid_df.index):\n",
    "    # do not re-download them\n",
    "    if vid_id in downloaded_ids:\n",
    "        continue\n",
    "    try:\n",
    "        video_handle = YouTube(f\"https://www.youtube.com/watch?v={vid_id}\", use_oauth=True, allow_oauth_cache=True)\n",
    "\n",
    "        video_stream = video_handle.streams.filter(\n",
    "            progressive=True,\n",
    "            file_extension='mp4',\n",
    "            resolution='720p'\n",
    "        ).first()\n",
    "\n",
    "        if video_stream:\n",
    "            video_stream.download(filename_prefix=f\"[{vid_id}]_\", output_path=VIDEO_DOWNLOAD_DIRECTORY, skip_existing=True)\n",
    "        else:\n",
    "            continue # TODO logging\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend the video data with video details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1053/1053 [00:07<00:00, 141.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tqdm import tqdm\n",
    "# Extend data with video details\n",
    "# I wanted to the properties of exactly the videos I have downloaded\n",
    "# this is why i did not use the Youtube API for this\n",
    "\n",
    "vid_df = load_video_data(VIDEO_DATA_PATH)\n",
    "\n",
    "downloaded_paths = glob(os.path.join(VIDEO_DOWNLOAD_DIRECTORY, \"*.mp4\"))\n",
    "downloaded_paths = dict(map(lambda x: (parse_video_file(x)['id'], x), downloaded_paths))\n",
    "\n",
    "vid_details = []\n",
    "for vid_id in tqdm(vid_df.index):\n",
    "    vid_path = downloaded_paths.get(vid_id, None)\n",
    "    if vid_path:\n",
    "        vid_cap = cv2.VideoCapture(vid_path)\n",
    "        vid_id = parse_video_file(vid_path)['id']\n",
    "        if (vid_cap.isOpened()):\n",
    "            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "            fr_cnt = int(vid_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            width = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            vid_details.append({\n",
    "                \"id\": vid_id,\n",
    "                \"video_available\": True,\n",
    "                \"fps\": fps,\n",
    "                \"frame_count\": fr_cnt,\n",
    "                \"frame_width\": width,\n",
    "                \"frame_height\": height\n",
    "            })\n",
    "        else:\n",
    "            vid_details.append({\n",
    "                \"id\": vid_id,\n",
    "                \"video_available\": False,\n",
    "                \"fps\": None,\n",
    "                \"frame_count\": None,\n",
    "                \"frame_width\": None,\n",
    "                \"frame_height\": None\n",
    "            })\n",
    "        vid_cap.release()\n",
    "    else:\n",
    "        vid_details.append({\n",
    "            \"id\": vid_id,\n",
    "            \"video_available\": False,\n",
    "            \"fps\": None,\n",
    "            \"frame_count\": None,\n",
    "            \"frame_width\": None,\n",
    "            \"frame_height\": None\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 videos were unavailable\n"
     ]
    }
   ],
   "source": [
    "vid_details_df = pd.DataFrame(vid_details)\n",
    "vid_details_df.set_index('id', inplace=True)\n",
    "print(f\"{sum(~vid_details_df['video_available'])} videos were unavailable\")\n",
    "vid_df = vid_df.drop(columns=vid_details_df.columns.intersection(vid_df.columns))\n",
    "vid_df = pd.merge(vid_df, vid_details_df, left_index=True, right_index=True)\n",
    "store_video_data(vid_df, VIDEO_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download transcripts (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_video_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vid_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_video_data\u001b[49m(VIDEO_DATA_PATH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_video_data' is not defined"
     ]
    }
   ],
   "source": [
    "vid_df = load_video_data(VIDEO_DATA_PATH)\n",
    "downloaded_vid_paths = glob(os.path.join(VIDEO_DOWNLOAD_DIRECTORY, \"*.mp4\"))\n",
    "downloaded_vid_paths = dict(map(lambda x: (parse_video_file(x)['id'], x), downloaded_vid_paths))\n",
    "\n",
    "downloaded_transcript_paths = glob(os.path.join(TRANSCRIPT_DOWNLOAD_DIRECTORY, \"*.json\"))\n",
    "get_id_from_transcript_filename = lambda x : os.path.splitext(os.path.basename(x))[0]\n",
    "downloaded_transcript_paths = dict(map(lambda x: (get_id_from_transcript_filename(x), x), downloaded_transcript_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from yt_dlp import YoutubeDL\n",
    "from urllib.request import urlopen\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "yt_opts = {\n",
    "    \"skip_download\": True,\n",
    "    #\"cookiefile\": r\"C:\\Users\\emaid\\Desktop\\guiagents\\data\\youtube.com_cookies.txt\",\n",
    "    \"cookiesfrombrowser\": ('chrome', ),\n",
    "    #\"listsubtitles\": True,\n",
    "    \"writeautosubtitles\": True,\n",
    "    \"subtitlesformat\": 'json3',\n",
    "    \"subtitlelangs\": ['all'],\n",
    "    \"nocheckcertificate\": True,\n",
    "    \"quiet\": True,\n",
    "    \n",
    "}\n",
    "\n",
    "def restructure_caption(caption_dict):\n",
    "    segs = caption_dict.get('segs', [])\n",
    "    caption_dict['text'] = \"\".join(map(lambda x: list(x.values())[0], segs))\n",
    "    return caption_dict\n",
    "\n",
    "with YoutubeDL(yt_opts) as yt: # if it doesnt auto load cookies then we could break this into yt = You.. and yt.close() when the exception happens\n",
    "    for vid_id in tqdm(vid_df.index):\n",
    "        if vid_id in downloaded_vid_paths.keys(): # only videos we have donwloaded so far make sense\n",
    "            if vid_id in downloaded_transcript_paths.keys(): # no need to download twice\n",
    "                continue\n",
    "            transcript = dict()\n",
    "            info = yt.extract_info(f\"https://www.youtube.com/watch?v={vid_id}\")\n",
    "            en_sub = info['subtitles'].get('en', None)\n",
    "            langs = info['subtitles'].keys()\n",
    "            langs = list(filter(lambda x: x=='en' or x.startswith('en-'), langs))\n",
    "            if len(langs) > 0: # if there is an english subtitle\n",
    "                en_sub = info['subtitles'][langs[0]]\n",
    "                transcript['generated'] = False\n",
    "            else:\n",
    "                en_sub = info['automatic_captions'].get('en', None)\n",
    "                if en_sub:\n",
    "                    transcript['generated'] = True\n",
    "                else:\n",
    "                    print(f'No automatic english captions found for {vid_id}!')\n",
    "                    continue\n",
    "\n",
    "            json_encodings = list(filter(lambda x: x['ext'] == 'json3', en_sub))\n",
    "            if len(json_encodings) > 0:\n",
    "                url = json_encodings[0]['url']\n",
    "                url_response = urlopen(url)\n",
    "                charset = url_response.info().get_content_charset()\n",
    "                ret_obj = json.loads(url_response.read().decode(charset)) # get json from response\n",
    "                if 'events' in ret_obj.keys():\n",
    "                    transcript['transcript'] = list(map(restructure_caption, ret_obj['events']))\n",
    "                else:\n",
    "                    print(f'Could not retreive events for {vid_id}!')\n",
    "                    continue\n",
    "                \n",
    "                with open(os.path.join(TRANSCRIPT_DOWNLOAD_DIRECTORY, f\"{vid_id}.json\"), \"w\") as transcript_file:\n",
    "                    json.dump(transcript, transcript_file, indent=4)\n",
    "            else:\n",
    "                print(f'{vid_id} is missing the json encoding!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is the old code for donwloading code currently doesnt work\n",
    "# if the library introduces a fix then it can be used again\n",
    "#from youtube_transcript_api import YouTubeTranscriptApi, NoTranscriptFound, NoTranscriptAvailable, TranscriptsDisabled\n",
    "#import traceback\n",
    "#from tqdm import tqdm\n",
    "#\n",
    "#transcripts = dict()\n",
    "#\n",
    "#for vid_id in tqdm(vid_df.index[:3]):\n",
    "#    try:\n",
    "#        transcript_list = YouTubeTranscriptApi.list_transcripts(vid_id)\n",
    "#        ts_handle = transcript_list.find_transcript(['en', 'en-GB', 'en-US', 'de', 'fr','es'])\n",
    "#        transcript = ts_handle.fetch()\n",
    "#        transcripts[vid_id] = {'is_generated': ts_handle.is_generated, 'availability': \"available\", 'message':\"\", 'transcript': transcript} \n",
    "#    except NoTranscriptFound as e:\n",
    "#        transcripts[vid_id] = {'is_generated': None, 'availability': \"not_found\", 'message': traceback.format_exc(), 'transcript': None} \n",
    "#    except NoTranscriptAvailable as e:\n",
    "#        transcripts[vid_id] = {'is_generated': None, 'availability': \"not_available\", 'message': traceback.format_exc(), 'transcript': None} \n",
    "#    except TranscriptsDisabled as e:\n",
    "#        transcripts[vid_id] = {'is_generated': None, 'availability': \"disabled\", 'message': traceback.format_exc(), 'transcript': None} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract images for data cleaning classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1N0L-FDWCs</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1N0L-FDWCs</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1N0L-FDWCs</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1N0L-FDWCs</td>\n",
       "      <td>3710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1N0L-FDWCs</td>\n",
       "      <td>7107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>zkiEtOay5ZA</td>\n",
       "      <td>1781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>zkiEtOay5ZA</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>zkiEtOay5ZA</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>zpwgKLGQDQg</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>zpwgKLGQDQg</td>\n",
       "      <td>4042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  frame\n",
       "0     -1N0L-FDWCs    214\n",
       "1     -1N0L-FDWCs    311\n",
       "2     -1N0L-FDWCs    934\n",
       "3     -1N0L-FDWCs   3710\n",
       "4     -1N0L-FDWCs   7107\n",
       "...           ...    ...\n",
       "9995  zkiEtOay5ZA   1781\n",
       "9996  zkiEtOay5ZA   2184\n",
       "9997  zkiEtOay5ZA   3010\n",
       "9998  zpwgKLGQDQg   2355\n",
       "9999  zpwgKLGQDQg   4042\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# Get the duration of all videos\n",
    "\n",
    "number_of_datapoints = 10000\n",
    "vid_df = load_video_data(VIDEO_DATA_PATH)\n",
    "vid_df = vid_df[vid_df['video_available']]\n",
    "vid_df.sort_index(inplace=True)\n",
    "\n",
    "# create interval ends\n",
    "ends = vid_df['frame_count'].astype(int).to_numpy().cumsum()\n",
    "\n",
    "# create interval starts\n",
    "starts = np.roll(ends, 1)\n",
    "starts[0] = 0\n",
    "\n",
    "# choose random frames from all possible frames\n",
    "total_frames = sum(vid_df['frame_count'])\n",
    "choices = np.sort(np.random.randint(0, total_frames, number_of_datapoints))\n",
    "\n",
    "# create interval matrix\n",
    "interval_matches = ((choices[np.newaxis, :] >= starts[:, np.newaxis]) & (choices[np.newaxis, :] < ends[:, np.newaxis]))\n",
    "\n",
    "# turn it into da pandas dataframe\n",
    "interval_matches = pd.DataFrame(interval_matches, index=vid_df.index, columns=choices)\n",
    "\n",
    "# Melt the columns into one\n",
    "interval_matches = interval_matches.melt(ignore_index=False, value_name=\"is_in\", var_name='frame').reset_index()\n",
    "\n",
    "# Keep only the frames that where in the correct interval\n",
    "interval_matches = interval_matches.query('is_in').drop(columns='is_in')\n",
    "\n",
    "starts_df = vid_df['frame_count'].shift(1, fill_value=0).cumsum().astype(int).reset_index()\n",
    "interval_matches = interval_matches.merge(starts_df, on=\"id\")\n",
    "frames_to_extract = pd.DataFrame({\"id\":interval_matches['id'], \"frame\": interval_matches['frame'] - interval_matches['frame_count']})\n",
    "frames_to_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "-1N0L-FDWCs           0.0\n",
       "-Ee1zsYFPgU      113587.0\n",
       "-F5TrmNdDLo      115993.0\n",
       "-QwrEVbyZkQ      123943.0\n",
       "-dcwIpH6GVs      129154.0\n",
       "                  ...    \n",
       "zkJkRCZ4_9o    20715686.0\n",
       "zkb1sZJNdyw    20734810.0\n",
       "zkiEtOay5ZA    20786850.0\n",
       "zpwgKLGQDQg    20790149.0\n",
       "zrZjecLrMWc    20797005.0\n",
       "Name: frame_count, Length: 1013, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_num = 5000\n",
    "v = (vid_df['frame_count'] - 5).cumsum().shift(1, fill_value=0)\n",
    "i = v.searchsorted(frame_num, side='right') - 1\n",
    "#frame_num - v.iloc[i]\n",
    "vid_df.index[i]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# The above cell creates a dataframe with two rows one being the id of a video and the other all of the frames to be extracted from the video\n",
    "# probably just to write a VideoCapture iterator that gets the needed frames saves them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running cursor tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1053/1053 [26:08:51<00:00, 89.39s/it]    \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch as pt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "vid_df = load_video_data(VIDEO_DATA_PATH)\n",
    "\n",
    "downloaded_paths = glob(os.path.join(VIDEO_DOWNLOAD_DIRECTORY, \"*.mp4\"))\n",
    "downloaded_paths = dict(map(lambda x: (parse_video_file(x)['id'], x), downloaded_paths))\n",
    "\n",
    "tracked_vid_ids = glob(os.path.join(YOLO_RESULTS_DIR, \"*.csv\"))\n",
    "tracked_vid_ids = set(map(lambda x: os.path.splitext(os.path.basename(x))[0], tracked_vid_ids)) # remove path and csv just get ids\n",
    "\n",
    "for vid_id in tqdm(vid_df.index):\n",
    "\n",
    "    try:\n",
    "        vid_path = downloaded_paths[vid_id]\n",
    "    except KeyError:\n",
    "        # TODO log file not found\n",
    "        continue\n",
    "\n",
    "    if not vid_id in tracked_vid_ids:\n",
    "\n",
    "        mouse_positions = []\n",
    "\n",
    "        # load video\n",
    "        cap = cv2.VideoCapture(vid_path)\n",
    "        ret = True\n",
    "        i = 0\n",
    "        while ret:\n",
    "            ret, img = cap.read()\n",
    "            if ret and (i % YOLO_TRACKING_FRAME_STEP == 0):\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                result = yolo_model.predict(img, verbose=False)[0]\n",
    "                time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "                if(sum(result.boxes.conf > YOLO_CONFIDENCE_THRESH) >= 1):\n",
    "                    x, y, w, h = result.boxes.xywh[pt.argmax(result.boxes.conf)].cpu().tolist()\n",
    "                    mouse_positions.append({\n",
    "                        'x': x,\n",
    "                        'y': y,\n",
    "                        'width': w,\n",
    "                        'heigth':h,\n",
    "                        'frame': i,\n",
    "                        'conf': pt.max(result.boxes.conf).item()\n",
    "                    })\n",
    "            i += 1\n",
    "        cap.release()\n",
    "\n",
    "        if len(mouse_positions) > 0:\n",
    "            mouse_df = pd.DataFrame(mouse_positions).set_index(\"frame\")\n",
    "            mouse_df.to_csv(os.path.join(YOLO_RESULTS_DIR, f\"{vid_id}.csv\"), float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO_RESULTS_DIR = \"../data/youtube_dataset/mouse_tracking\"\n",
    "\n",
    "for mt_path in glob(os.path.join(YOLO_RESULTS_DIR, '*.csv')):\n",
    "    vid_id = os.path.splitext(os.path.basename(mt_path))[0]\n",
    "    mt = pd.read_csv(mt_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Validation and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_df = load_video_data(VIDEO_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "ids = vid_df.index.to_numpy().copy()\n",
    "np.random.shuffle(ids)\n",
    "splits = np.array([0.7, 0.15, 0.15])\n",
    "splits = np.round(np.cumsum(splits) * len(ids)).astype(int)\n",
    "train_ids, val_ids, test_ids, _  = np.split(ids, splits)\n",
    "train_vid_df = vid_df.loc[train_ids]\n",
    "val_vid_df = vid_df.loc[val_ids]\n",
    "test_vid_df = vid_df.loc[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_video_data(train_vid_df, data_path=TRAIN_DATA_PATH)\n",
    "store_video_data(val_vid_df, data_path=VAL_DATA_PATH)\n",
    "store_video_data(test_vid_df, data_path=TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "sequences = []\n",
    "for mt_path in tqdm(glob(os.path.join(YOLO_RESULTS_DIR, '*.csv'))):\n",
    "    vid_id = os.path.splitext(os.path.basename(mt_path))[0]\n",
    "    mt = pd.read_csv(mt_path)\n",
    "    mt = mt.query(\"conf>0.85\")\n",
    "    if(len(mt)<150):\n",
    "        continue\n",
    "    frames = np.arange(0, np.max(mt['frame'])+1, 3, dtype=int)\n",
    "    # moving\n",
    "    mouse_moving = np.zeros(len(frames))\n",
    "    mouse_moving[mt[np.sqrt(mt['x']**2 + mt['y']**2) > 2*mt['heigth']]['frame']//3] = 1\n",
    "    mouse_moving_rolling = np.convolve(mouse_moving, np.ones(100)/100, 'same') - 0.5\n",
    "\n",
    "    # is present\n",
    "    mouse_present = np.zeros(len(frames))\n",
    "    mouse_present[mt['frame']//3] = 1\n",
    "    mouse_present_rolling = np.convolve(mouse_present, np.ones(100)/100, 'same') - 0.85\n",
    "    mouse =  np.minimum(mouse_present_rolling, mouse_moving_rolling)\n",
    "    ispos = np.concatenate(([0], (mouse > 0).view(np.int8), [0]))\n",
    "    absdiff = np.abs(np.diff(ispos))\n",
    "    clean_intervals = np.where(absdiff == 1)[0]*3\n",
    "    clean_intervals = clean_intervals.reshape(-1, 2)\n",
    "    big_enough = (np.diff(clean_intervals, axis=1) >= 150)\n",
    "    clean_intervals = clean_intervals[big_enough.flatten()]\n",
    "    if(len(clean_intervals) == 0):\n",
    "        continue\n",
    "    def interval_to_seqs(interval):\n",
    "        steps = np.arange(interval[0], interval[1] - 150, 50)\n",
    "        intervals = np.stack((steps, steps + 150), axis=1)\n",
    "        return intervals\n",
    "    seqs = list(map(interval_to_seqs, clean_intervals))[0]\n",
    "    if(len(seqs) > 0):\n",
    "        out = []\n",
    "        for interval in seqs:\n",
    "            mt_interval = mt.query(\"frame >= @interval[0] and frame <= @interval[1]\")\n",
    "            if(mt.query(\"frame >= @interval[0] and frame < @interval[1]\").empty):\n",
    "                print('HI')\n",
    "                print(interval)\n",
    "            out.append((vid_id, interval, mt_interval))\n",
    "        sequences.extend(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
